#!/bin/bash

echo "ğŸš€ Starting K-AI Pharmaceutical Chatbot..."
echo "ğŸ“ Current directory: $(pwd)"

# Check if Docker is running
if ! docker info > /dev/null 2>&1; then
    echo "âŒ Docker is not running. Please start Docker Desktop and try again."
    exit 1
fi

echo "âœ… Docker is running"

# Start Ollama if not running
if ! pgrep -f "ollama serve" > /dev/null; then
    echo "ğŸ¤– Starting Ollama local LLM server..."
    ollama serve &
    sleep 5
else
    echo "âœ… Ollama is already running"
fi

# Navigate to deployment directory
cd deployment

echo "ğŸ”§ Starting K-AI services..."
docker-compose -f docker-compose.yaml up -d

echo "â³ Waiting for services to start..."
sleep 15

echo "ğŸŒ Opening K-AI in your browser..."
open "http://localhost:5173"

echo ""
echo "ğŸ‰ K-AI Pharmaceutical Chatbot is now running!"
echo "ğŸ“± Access your chatbot at: http://localhost:5173"
echo ""
echo "ğŸ“‹ To stop K-AI later, run:"
echo "   docker-compose -f deployment/docker-compose.yaml down"
echo ""
echo "ğŸ’¡ Using local Ollama with Llama 3.2 3B model"
echo "ğŸ”’ All pharmaceutical documents stay private on your Mac"
echo "ğŸ“š Ready to chat about pharmaceutical SOPs and GMP!"

# Keep terminal open
read -p "Press Enter to close this window..."